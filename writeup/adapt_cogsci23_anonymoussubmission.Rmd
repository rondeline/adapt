---
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
# author-information: >
   
abstract: >
  
keywords: >
  active learning; associative learning; auditory noise; cognitive development; decision making
      
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      message=F, sanitize = T)
```

```{r libraries}
library(png)
library(grid)
library(xtable)
library(tidyverse)
library(ggthemes)
library(janitor)
library(rstanarm)
library(here)
library(stats)
library(lme4)
library(gtsummary)
# library(gtsummary)
library(reprex)
library(wesanderson)

```

# Introduction









# Experiment 1

In our first experiment, we evaluated preschool children's environmental selection, their integration of both auditory information and a third party's goals, for familiar activities. We asked whether they would differentially select environment-goal pairings that optimized another person's goals. If children are systematically pairing based on outcomes, this may suggest that they are, in fact, attuned to the environment as a strategy for goal optimization. 

## Methods

```{r e1-data}

## Load data
data_3b <- read_csv(here("data", "childrendatalog3b.csv"))

## Tidy data
tidydata_3b <- data_3b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "Yes") %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

## Remove extra spaces
tidydata_3b$activity <- str_trim(tidydata_3b$activity)
tidydata_3b$sound_type <- str_trim(tidydata_3b$sound_type)
tidydata_3b$race <- str_trim(tidydata_3b$race)
tidydata_3b$race <- str_replace(tidydata_3b$race, "/ ", "/")

## Turn response column into integers
tidydata_3b$response <- as.integer(tidydata_3b$response)

## Scale Age
tidydata_3b$age_centered <- scale(tidydata_3b$age_months, scale = FALSE)

## Get demographic data
demodata_3b <- tidydata_3b %>%
  select(subject_id,race, trial, age_years, age_months) %>%
  filter(trial == 1) %>%  #get one value per participant
  mutate(race_count = ifelse((str_detect(race, ",")), "Multiracial", race))

excluded_3b <- data_3b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "No",
         trial == 1) %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

```

### Participants

`r nrow(demodata_3b)` children (3;0 - 5;11 years, mean age = `r round(mean(demodata_3b$age_months/12),2)` years , `r round(mean(demodata_3b$race == "Caucasian/White")*100,1)`% Caucasian/White) were recruited from either a local Bay Area nursery school or childrenâ€™s museum. Participants were typically developing, had normal or corrected-to-normal vision, and heard English at least 75% of the time at home. An additional `r nrow(excluded_3b)` children were ultimately excluded from analysis due to response bias (provided the same pattern of responses for 100% of trials), experimenter error, or severe lapses in attention. All exclusion criteria were preregistered. Caregivers provided written consent while children provided verbal assent before participation. 

### Materials and Procedure

```{r e3-stimuli, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=3, fig.height=3, set.cap.width=T, fig.cap = "Experimental setup and stimuli. Participants were shown four wooden houses, each with an associated sound [instrumental music, multi-talker babble, silence, and white noise], and a list of four activities [dance, read, sleep, talk] that two charactrs in the game wanted to complete. Participants determined whether the two characters should or should not complete an activity in each of the four houses. Responses were independent of each other."}
figure1_23 <- png::readPNG(here("writeup","figs","figure1_23.png"))
grid::grid.raster(figure1_23)
```

A trained undergraduate research assistant served as the experimenter for the task. The experimenter first introduced participants to two small plastic figures named Joe and Mandy and to four wooden houses with a felt door on the front. The experimenter then showed participants a list of four images, each depicting one activity Joe and Mandy wanted to do together. The experimenter explained that when the door opened, each house would either play a sound or it wouldn't play anything at all. Joe and Mandy could choose whether or not to complete an activity in each house, and their decisions would be entirely based on participants' responses. Importantly, these decisions were independent of each other; participants could decide to have Joe and Mandy complete the same activity in more than one room if appropriate. A sound button was attached to the back of each house and hidden from the participant's view so when the experimenter opened the door, they also pressed down on the button to play the appropriate sound. The wooden houses were lined up on a table several inches apart with the participant seated facing the door of the house and the experimenter on the opposite side facing the sound buttons. Figure 1 illustrates the setup, the four activities, and the four auditory stimuli. 



We asked participants two questions which served as our DVs: (1) "Should Joe and Mandy [read/dance/sleep/talk] in this room?" and (2) "Why did you say Joe and Mandy [should/shouldn't] [read/dance/sleep/talk] in this room?" 

## Results and Discussion

```{r e3b-bar, fig.pos = "t", fig.align='center', fig.width=7, fig.height=4, fig.env = 'figure*', fig.cap= "Results from Experiment 1. Participants' rating of the appropriateness of an auditory stimulus and activity pairing. Individual bars correspond to one age bin of 3, 4, or 5. A rating score of 0 indicates a rejection of the pairing [Joe and Mandy should not complete a particular activity in this environment] while a score of 1 indicates an affirmation of the pairing [Joe and Mandy should complete a particular activity in this environment]. A 2-alternative forced choice design resulted in no preference at 50\\%.  Error bars show 95\\% confidence intervals."}

## Calculate confidence intervals

### Aggregate confidence intervals (3-5 years)
cidata_3b <- tidydata_3b %>%
  group_by(activity, sound_type) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

### Binned confidence intervals (by age)
cidataage_3b <- tidydata_3b %>%
  group_by(activity, sound_type, age_years) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

# Data visualization and stats

## labels
xlabels <- c(mtb5 = "babble",
             instrumental = "music",
             silence = "silence",
             white = "white noise")
facet_labels_3b <- c(dance = "Dance", 
                  read = "Read",
                  sleep = "Sleep",
                  talk = "Talk")

## Figure 2
### Binned Data
ggplot(data = cidataage_3b, mapping = aes(x = factor(sound_type, level= c("mtb5", "instrumental", "silence", "white")), fill = as.factor(age_years))) +
  geom_bar(aes(y = mean_response),
           position = "dodge", stat = "identity") +
  geom_linerange(aes(ymin = ci.l,
                     ymax = ci.u),
                 position = position_dodge(width = 0.9)) +
  facet_wrap(~activity, labeller = as_labeller(facet_labels_3b), scales = "free", ncol = 4) +
  xlab("Auditory Stimulus") +
  ylim(0,1) +
  ylab("Rating") +
  scale_fill_manual(values = wes_palette("GrandBudapest1")) +
  scale_x_discrete(labels = xlabels) +
  geom_hline(yintercept = .5, lty =2) +
  theme_few() +
  theme(axis.text = element_text(size = 8),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        panel.spacing.x = unit(0.25, "lines"),
        panel.spacing.y = unit(0.25, "lines"),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.x = element_text(angle = 30, hjust=1),
        text = element_text(size = 10)) +
  labs(fill = "Age (Years)")

```

```{r e3-stats-anova, echo=FALSE, results="hide", eval=FALSE}
mod <- lme4::glmer(response ~ sound_type * activity + (1|subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"),
                   data = tidydata_3b)
mod_noint <- lme4::glmer(response ~ sound_type + activity + (1|subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"), 
                   data = tidydata_3b)

options(scipen = 999)   
anova_3b <- anova(mod,mod_noint)

<<<<<<< HEAD
=======
# aov()

>>>>>>> a7fec9956560f8559583e1d22dc082ce01c80353
saveRDS(anova_3b, here("writeup/models","anova_3b.Rds"))

```

```{r e3-stats, echo=FALSE, results="hide", eval=FALSE}

tidydata_3b$activity <- factor(tidydata_3b$activity, 
                                   levels = c("dance","read","sleep","talk"))

glmer_3b <- stan_glmer(formula = response ~ sound_type * activity * age_centered + (1 | subject_id),
                       family = binomial,
                       data = tidydata_3b)

contr.sum(16)

summary_3b <- summary(glmer_3b, probs = c(0.025, 0.975))

saveRDS(summary_3b, here("writeup/models","summary_3b.Rds"))
```

```{r e3-stats-load}
summary_3b<- readRDS(here("writeup/models","summary_3b.Rds"))
anova_3b <- readRDS(here("writeup/models","anova_3b.Rds"))
```





# Experiment 2




While some unifying accounts of active and associative learning exist [see @kruschke2008], traditional associative accounts view the learner as a passive agent, one who learns what is true about their environment but does not necessarily act on their environment. It is possible that reasoning about the acoustic environment, while beneficial, is not necessary for goal optimization. In other words, perhaps children can still reach the same decision point with association alone. To test this, we replaced the familiar activities in Experiment 1 with novel ones. If children primarily reason about the pairing between the acoustic environment and a set of goals through pure association, they should have trouble pairing acoustic environments with novel activities because they have not previously reasoned about these pairings. If, however, children are actively updating information about their environment and then using this information to inform new goals, they should also succeed even when faced with goals they have never encountered.

## Methods

```{r e4-data}
#CHILDREN
## Load data
data_4b <- read_csv(here("data", "childrendatalog4b.csv")) #load data

## Tidy data
tidydata_4b <- data_4b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "Yes") %>% #exclude pilot participants and those who could not be retained for analysis failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

## Remove extra spaces
tidydata_4b$activity <- str_trim(tidydata_4b$activity)
tidydata_4b$sound_type <- str_trim(tidydata_4b$sound_type)
tidydata_4b$race <- str_trim(tidydata_4b$race)
tidydata_4b$race <- str_replace(tidydata_4b$race, "$/$ ", "$/$")

## Turn response column into integers
tidydata_4b$response <- as.integer(tidydata_4b$response)
tidydata_4b$age_months <- as.integer(tidydata_4b$age_months)

## Scale Age
tidydata_4b$age_centered <- scale(tidydata_4b$age_months, scale = FALSE)

## Demographic information
demodata_4b <- tidydata_4b %>%
  select(subject_id,race, trial, age_years, age_months) %>%
  filter(trial == 1) %>%  #get one value per participant
  mutate(race_count = ifelse((str_detect(race, ",")), "Multiracial", race)) 

excluded_4b <- data_4b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "No",
         trial == 1) %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale)
```

```{r e4adult-data}
#ADULTS
#Load data 4a
data_4a <- read.csv(here("data", "adultdatalog4a1.csv"), na.strings = c("", "NA")) #load data

## Clean data
cleandata_4a <- data_4a %>% 
  clean_names() %>% #lowercase column names
  select(q6:language_1) %>% #remove unnecessary columns
  rename("sound_check" = "q6")

## Remove first two rows (contain no data/are unnecessary)
cleandata_4a <- cleandata_4a[-c(1,2), ]

## Data cleaning and participant exclusion
tidydata_4a <- cleandata_4a %>% 
  filter(attention_check_1 == 1,
         attention_check_2 == 1,
         sound_check == 1) %>% #exclude participants who failed attention and sound checks
  mutate(subject_id = row_number()) %>% #make a subject id column
  select(subject_id, everything()) %>%
  relocate(age, race, .after = subject_id) %>% 
  select(subject_id:rast_white)

## Pivot columns
tidy4a <- tidydata_4a %>%
  pivot_longer(cols = c("clop_instrumental", "fraw_instrumental", "gobb_instrumental", "norl_instrumental", "terb_instrumental", "plip_instrumental", "surk_instrumental", "rast_instrumental",
                        "clop_silence", "fraw_silence", "gobb_silence", "norl_silence", "terb_silence", "plip_silence", "surk_silence", "rast_silence",
                        "clop_white", "fraw_white", "gobb_white", "norl_white", "terb_white", "plip_white", "surk_white", "rast_white",
                        "clop_mtb", "fraw_mtb", "gobb_mtb", "norl_mtb", "terb_mtb", "plip_mtb", "surk_mtb", "rast_mtb"),
               names_to = "activity",
               values_to = "rating") %>% 
  separate(col = activity,
           into = c("activity", "noise_type"),
           sep = '[_]') %>% 
  na.omit()

## Make rating category numeric
tidy4a$rating <- as.integer(tidy4a$rating)

##Pull out 4 activities that relate to Experiment 2
tidydata_4a_exp2 <- tidy4a %>% 
  filter(activity %in% c("fraw", "gobb", "plip", "clop")) %>%
  rename("activity_old" = "activity") %>% 
  mutate(activity = case_when(
            activity_old == "clop" ~ "terb",
            activity_old == "gobb" ~ "gobb",
            activity_old == "fraw" ~ "fraw",
            activity_old == "plip" ~ "plip"))

## Demographic information
demodata_4a <- tidydata_4a %>%
  select(subject_id,age, race) %>% 
  replace(is.na(tidydata_4a$race), 7)

## Make race and age categories numeric
demodata_4a$race <- as.integer(demodata_4a$race, na.rm = TRUE)
demodata_4a$age <- as.integer(demodata_4a$age, na.rm = TRUE)

excluded_4a <- cleandata_4a %>%
  filter(attention_check_1 == 0 | attention_check_2 == 0)

```

### Participants


### Materials and Procedure

The procedures for Experiment 2 were nearly identical to Experiment 1 with one notable difference. To determine whether preschool children use environmental selection flexibly to novel activities, we presented participants with a new list of activities- (1) Fraw: when someone reads you a bedtime story right before you fall asleep, (2) Gobb: when you are looking for something to do because you are really bored, (3) Plip: when you spin around in circles to the beat until you get really dizzy, and (4) Terb: when you don't want anyone else to know your tummy is making noise. We selected these novel activities based on an adult sample we previously ran online, where we found these four activities elicited the widest distribution of responses among participants. 

We asked participants two questions which served as our DVs: (1) "Should Joe and Mandy [fraw/gobb/plip/terb] in this room?" and (2) "Why did you say Joe and Mandy [should/shouldn't] [fraw/gobb/plip/terb] in this room?"

## Results and Discussion

```{r e4b-bar, fig.env = "figure*", fig.pos = "t", fig.align='center', fig.width=7, fig.height=4, fig.cap = "Results from Experiment 2. Data is collapsed acrossed age."}
#CHILDREN
## Calculate confidence intervals

### Aggregate confidence intervals (3-5 years)
cidata_4b <- tidydata_4b %>%
  group_by(activity, sound_type) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

### Binned confidence intervals (by age)
cidataage_4b <- tidydata_4b %>%
  group_by(activity, sound_type, age_years) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

# Data visualization and stats

## x-axis labels
xlabels <- c("5tb" = "babble",
             instrumental = "music",
             silence = "silence",
             white = "white noise")
facet_labels <- c(fraw = "Fraw: read before bed", 
                  gobb = "Gobb: look for something to do",
                  plip = "Plip: spin in circles",
                  terb = "Terb: hide stomach grumbling")

#Figure 3
 ## Aggregated Data
 ggplot(data = cidata_4b, mapping = aes(x = factor(sound_type, level= c("5tb", "instrumental", "silence", "white")), y = mean_response, fill = activity)) +
   geom_col() +
   geom_linerange(aes(ymin = ci.l,
                      ymax = ci.u)) +
   ylim(0,1) +
   xlab("Auditory Stimulus") +
   ylab("Rating") +
   #scale_fill_brewer(palette="Set2") +
   scale_fill_manual(values = wes_palette("GrandBudapest1")) +
   scale_x_discrete(labels = xlabels) +
   facet_wrap(~activity, labeller = as_labeller(facet_labels)) +
   geom_hline(yintercept = .5, lty =2) +
   scale_color_solarized() + 
   theme_few() +
   theme(legend.position = "none",
         title = element_text(size = 8),
         axis.text = element_text(size = 8),
         panel.spacing.x = unit(0.5, "lines"),
         panel.spacing.y = unit(0.5, "lines"),
         axis.text.x = element_text(angle = 30, hjust=1),
         text = element_text(size=10))

## Binned Data
# ggplot(data = cidataage_4b, mapping = aes(x = sound_type, fill = as.factor(age_years))) +
#   geom_bar(aes(y = mean_response),
#            position = "dodge", stat = "identity") +
#   geom_linerange(aes(ymin = ci.l,
#                      ymax = ci.u),
#                  position = position_dodge(width = 0.9)) +
#   facet_wrap(~activity, scales = "free", ncol = 4) +
#   xlab("Auditory Stimulus") +
#   ylim(0,1) +
#   ylab("Rating") +
#   scale_fill_manual(values = wes_palette("GrandBudapest1")) +
#   scale_x_discrete(labels = xlabels) +
#   geom_hline(yintercept = .5, lty =2) +
#   theme_few() +
#   theme(axis.text = element_text(size = 8),
#         legend.text = element_text(size = 8),
#         legend.title = element_text(size = 8),
#         panel.spacing.x = unit(0.25, "lines"),
#         panel.spacing.y = unit(0.25, "lines"),
#         legend.direction = "horizontal",
#         legend.position = "bottom",
#         axis.text.x = element_text(angle = 30, hjust=1),
#         text = element_text(size = 10)) +
#   labs(fill = "Age (Years)")
```


```{r e4-stats, results="hide", eval=FALSE}

# Logistic Regression
                       family = binomial,
                       data = tidydata_4b)

summary_4b_simple <- summary(glmer_4b_simple, probs = c(0.025, 0.975))


```

```

#ADULTS
## Calculate confidence intervals
cidata_4a <- tidydata_4a_exp2 %>%
  group_by(activity, noise_type) %>% 
  summarise(n = n(),
            mean_rating = mean(rating, na.rm=TRUE), 
            sem = sd(rating) / sqrt(n),
            ci.l = mean_rating - sem * 1.96,
            ci.u = mean_rating + sem * 1.96)

# Data Visualization

xlabels <- c(mtb = "babble",
             instrumental = "music",
             silence = "silence",
             white = "white noise")
facet_labels <- c(fraw = "Fraw: read before bed", 
                  gobb = "Gobb: look for something to do",
                  plip = "Plip: spin in circles",
                  terb = "Terb: hide stomach grumbling")
# Figure 4
ggplot(data = cidata_4a, 
       mapping = aes(x = factor(noise_type, level= c("mtb", "instrumental", "silence", "white")), y = mean_rating, fill = activity)) +
  geom_col() +
  geom_linerange(aes(ymin = ci.l,
                     ymax = ci.u)) +
  ylim(0,7) +
  xlab("Auditory Stimulus") +
  ylab("Rating") +
  #scale_fill_brewer(palette="Set2") +
  scale_fill_manual(values = wes_palette("GrandBudapest1")) +
  scale_x_discrete(labels = xlabels) +
  facet_wrap(~activity, labeller = as_labeller(facet_labels)) +
  geom_hline(yintercept = 3.5, lty =2) +
  scale_color_solarized() + 
  theme_few() +
  theme(legend.position = "none",
        title = element_text(size = 8),
        axis.text = element_text(size = 8),
        panel.spacing.x = unit(0.5, "lines"),
        panel.spacing.y = unit(0.5, "lines"),
        axis.text.x = element_text(angle = 30, hjust=1),
        text = element_text(size=10))

```

```{r e4a-stats-anova, results='hide', eval=FALSE}

mod4a <- lme4::lmer(rating ~ noise_type * activity  + (1 | subject_id), 
                  control = lmerControl(optimizer = "bobyqa"), 
                   data = tidy_data4a_exp2)
mod4a_noint <- lme4::lmer(rating ~ noise_type + activity  + (1 | subject_id),
                  control = lmerControl(optimizer = "bobyqa"), 
                   data = tidy_data4a_exp2)

anova_4a <- anova(mod4a, mod4a_noint)

saveRDS(anova_4a, here("writeup/models","anova_4a.Rds"))
```

```{r e4a-stats-anova-load}
anova_4a <- readRDS(here("writeup/models","anova_4a.Rds"))
```

```{r e4a-stats, results="hide", eval=FALSE}

# Logistic Regression
glmer_4a <- stan_glmer(formula = rating ~ noise_type * activity + (1 | subject_id),
                       data = tidy_data4a_exp2)

summary_4a <- summary(glmer_4a, probs = c(0.025, 0.975))

saveRDS(summary_4a, here("writeup/models","summary_4a.Rds"))

```

```{r e4a-stats-load}
summary_4a <- readRDS(here("writeup/models","summary_4a.Rds"))
```

If preschool children rely solely on association when evaluating the acoustic environment, that is, they have acquired associative links between familiar activities and their acoustic contexts, we should expect that children will have no strong preferences for pairing novel activities with any particular acoustic context. If, however, children can reason flexibly about how the acoustic environment influences goal optimization and outcomes, we should expect that children show clear preferences for acoustic contexts even with activities they have never actually encountered.

Data collection for Experiment 2 is ongoing, so we present a subset [20 of the preregistered 72-participant sample] of the data for preliminary analysis. Our model with an interaction between activity and auditory stimulus was not different from a model with no interaction term [$X^2$(`r anova_4b[2,7]`) = `r round(anova_4b[2,6],2)`, p = `r round(anova_4b[2,8],2)`]. Figure 3 shows the aggregated data across all participants.

## Adult Ratings of Novel Activity Pairings

The previous findings suggest some differentiation in pairing auditory stimuli with novel activities, but what pattern of results should we expect? Given the novelty of the paradigm, we recruited a sample of adult participants to complete the same task, and then we compared these results with children in the previous sample. 

### Participants
`r nrow(demodata_4a)` adults (mean age = `r round(mean(demodata_4a$age),2)` years, `r round(mean(demodata_4a$race == 3)*100,1)`% Caucasian/White) were recruited for an online study hosted on Prolific. An additional `r nrow(excluded_4a)` participants were ultimately excluded from analysis for failing one or both of the attention checks.

### Methods and Procedure
Participants completed a similar paradigm to children that was adapted to an online, self-paced task. Participants watched animated videos of a hallway exterior with one door centered in the middle of the screen. When the door opened, one of four sounds played, followed by the door closing at the end of the video. Each video was 7s in length and equalized to 65dB. Participants then responded to the following prompt: "I could [fraw/gobb/plip/terb] in this room", and were also provided with the definition of each. Responses were collected via a likert rating scale from 1 ("not at all well") to 7 ("very well"). Each novel activity was presented one at a time, and the presentation order was counterbalanced across participants.

### Results and Discussion
Figure 4 depicts adults' ratings for each activity by auditory stimulus. Our model with an interaction term was significantly different from the model with no such interaction [$X^2$(`r anova_4a[2,7]`) = `r round(anova_4a[2,6],2)`, p = `r round(anova_4a[2,8],2)`]. More importantly, the trend

In this set of experiments, we explored preschool children's reasoning about their acoustic environments and asked if children engage in environmental selection to find environments that are consistent with particular activities. In Experiment 1, we found that across the preschool years, children can reliably evaluate the acoustic environment to inform their decisions about third-party goals. In Experiment 2, we asked whether children are primarily relying on associations or on active learning when assessing activity feasibility by asking them to reason about novel activities. Preliminary results show a trend in children's flexibility on this task, such that they can reason about activities they have not previously encountered.

These findings support the notion that young children are attuned to environmental features and can integrate this information for decision-making related to optimizing goals. That learning is situated in an imperfect and often messy environment is all the more reason why strategic exploration matters. If you can identify what is best learned in a particular environment given the acoustic constraints, you might both maximize your efficiency and reduce uncertainty, which bolsters skills building. Environmental selection offers a window into reasoning about the acoustic context, and it highlights the value of active learning in early childhood. Perhaps most advantageous, active learning seems to be flexible, and supports children's exploration across a range of experiences.

This work is not without its limitations, which fuel our future directions. Without our full sample size in Experiment 2, we are limited in what we can conclude about the results. However, the preliminary findings are promising, and they offer some ground for broaching our main research questions. Additionally, this set of experiments explored children's reasoning about the goals of others; it is possible that children's preferences for certain acoustic environments may vary if they were instead asked to reason about their own goals. This work also does not directly test a strategy children might use to extract information from the environment under noise constraints. Instead, it lays the foundation for understanding how children evaluate acoustic environments with varying degrees of noise, and a possible mechanism that drives it. By exploring children's environmental evaluations and their flexibility beyond familiar associations, we might later manipulate children's own acoustic environments to observe the utility of environmental selection in action. We believe the current studies are critical interim steps to this end because they will inform the direction of future research.

This research also has potential utility in intervention efforts. Environmental noise exposure is here to stay; noise pollution in the United States affects everyone at some time or another, but some evidence suggests that it disproportionately affects communities of color and those of lower socioeconomic status, who tend to reside in more densely populated regions [@casey2017]. This could have downstream consequences on linguistic and cognitive skills, as well as on academic achievement. Future research should be sensitive to both the acute and chronic effects of noise exposure on children, in particular, and study strategies that can be implemented to ameliorate these effects. We believe that environmental selection could be one such strategy, and that by three years, children have the hardware to use it effectively. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

