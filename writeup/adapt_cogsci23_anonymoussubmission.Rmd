---
title: "Active? Associative?: Preschool children assess the feasibility of a goal based on the acoustic environment"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"
# author-information: >
   
abstract: >
  Despite the unpredictible and ubiquitous nature of noise in the natural environment, most children still manage to extract the linguistic, cognitive, and social skills needed to engage typically with the world around them. This is no small feat; it is still largely unknown what strategies children use to extract information from their environment in the presence of noise. One possbility is that children have learned how to reason about their acoustic context to optimize goals and goal outcomes. In Experiment 1, we presented preschool children with a set of auditory stimuli, meant to approximate various acoustic environments, and activity goals to complete within those environments. Results showed that children reliably integrated auditory information with a third-party's changing goals to optimize another person's outcomes. Experiment 2 built on this framework by replacing familiar activity goals with novel ones to assess the flexibility of children's decision-making, and offers some preliminary findings. 
  
keywords: >
  active learning; associative learning; auditory noise; cognitive development; decision making
      
output: cogsci2016::cogsci_paper
final-submission: \cogscifinalcopy
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=FALSE, 
                      message=F, sanitize = T)
```

```{r libraries}
library(png)
library(grid)
library(xtable)
library(tidyverse)
library(ggthemes)
library(janitor)
library(rstanarm)
library(here)
library(stats)
library(lme4)
library(gtsummary)
library(reprex)
library(wesanderson)

```

# Introduction

Children are excavators; they routinely build linguistic, cognitive, social, and emotional skills through interacting with their environments. They can adjust their attention to linguistic stimuli such as grammar based on its present learnability [@gerken2011]. They can exploit the emotional expressions of others to determine whether a novel object is worth exploration, thereby maximizing efficiency [@wu2021]. And when they do explore, children are often accounting for both the structure of the environment and their present goals to decide on a reasonable approach [@meder2021]. This flexibility in the learning system is highly adaptive, as it offers a means for data extraction even in unfamiliar or suboptimal learning conditions. 

We can understand why children are such flexible learners across a diverse range of environments through the lens of active learning. In this account, children make decisions about what and how they learn, which contrasts with the more passive view that they merely absorb information presented to them without an opportunity to make adjustments [@raz2020]. The active learning literature has typically explored children's interactions with individual stimuli within the environment [e.g., @settles2009]. For example, previous work has shown that preschool children use active learning strategies to approach objects in a novel task in order to optimize performance [@ruggeri2019]. In this task, children either opened or shook two sets of boxes, one of which contained an egg shaker. When children were told that the egg shaker was equally likely to be found in either set of boxes, they were more likely to shake the boxes first than when they were told the shaker was more likely to be found in a particular set of boxes. Even infants harness the utility of active learning by updating their expectations about what could be learned from an object that behaved unexpectedly, such as a ball moving through a solid wall [@stahl2015]. Additionally, infants as young as 7 months have been shown to efficiently allocate their attention to visual stimuli that are neither too complex nor too simple [@kidd2012]. 

A traditional account of active learning considers how children engage with individual stimuli within their environment to harness new information. But more recent work has considered how children reason about the environmental structure for learning as well. This type of active learning has been defined as ecological active learning, and it requires children to both identify features of their environment that are stable but influential, and then adjust their exploration strategies to maximize learning within this ecology [@ruggeri2022]. Ecological active learning proposes that the very structure of the environment, and not merely individual stimuli within it, is critical for information-seeking. Without a consideration for the constraints of the environment itself, it may be difficult to maximize efficiency and obtain new information.

Ecological active learning encourages an emphasis on environmental features that impact exploration. Given that children with access to auditory input can learn a great deal from their acoustic environment, is it also possible that they can reason about how well their acoustic environment supports goal optimization? In other words, what if children are using acoustic information from the environment to decide how to interact with the environment?

An acoustic environment can be flexibly defined, so we refer to it as the physical space in which the child interacts both in and on, and one that moves with the child. In this environment, children may adjust their engagement based on both auditory information and previously defined goals. For example, a child might choose to read or be read to in a library or in an empty room because a quiet space best aligns with the goal of taking in a storybook. We refer to this as environmental selection, the preferential process of selecting environments that align with goal optimization. It is preferential because it necessitates that children prioritize learning opportunities that are best suited for the present environment. This means that children identify a range of possible learning opportunities within the current environmental structure. They then constrain this range to those that can be optimized by maximizing learnability or efficiency, or by reducing uncertainty. Environmental selection is also goal-directed; children integrate information about their environment because they are motivated to achieve some outcome. Importantly, direct control over the environment is not a requisite for environmental selection. Instead, it suggests that given the present environment and having no intervening power on it, children will engage in activities that align with this environment, and they will exploit the variation across environments to achieve a range of goals that would have been less efficient under a single set of conditions. 

Environmental selection emphasizes acoustic information because it is both a salient feature of an environment and can have cascading effects on learning and development. The latter is especially true given the potential for auditory noise which may disrupt learning.  We define noise here as any stimulus that is unwanted or unattended to by the listener, and can be either internal to the system [i.e. errors in production or perception, or a limited linguistic repertoire], or external [i.e. the chatter of a busy coffee shop on Friday afternoon] [@shannon1948; @gibson2013]. Noise in the auditory channel has serious implications for active learning, especially for young children. Children are notably worse than adults at skills such as speech perception and word recognition in noise [@bjorklund1990; @klatte2013], and exhibit real challenges in word learning under background noise constraints [@mcmillan2016]. Because noise generally increases cognitive load during certain attention and spatial tasks, children are less able to flexibly adapt strategies to successfully complete these tasks than adults [@loh2022]. There is also emerging evidence that high levels of sustained noise exposure changes the cortical thickness of the left inferior frontal gyrus in infants [@simon2022]. Importantly, these effects of noise are not happening exclusively at the unconscious level; even young children are perceptually aware of excessive noise exposure [@mcallister2019]. With this in mind, we propose that environmental selection may be an adaptive strategy for learning in a variety of acoustic environments.

In the current paper, we studied both whether and how preschool children use environmental selection for goal optimization. In Experiment 1, we asked children to match a set of goals to one or more auditory environments where appropriate. Then in Experiment 2, we presented children with novel activities and asked them to complete the same task to explore the conceptual boundaries of this ability. Taken together, this set of experiments aims to expand our understanding of how children can exploit their acoustic environment for goal optimization across a range of inputs. 

# Experiment 1

In our first Experiment, we evaluated preschool children's environmental selection, their integration of both auditory information and a third party's goals, for familiar activities. We asked whether they would differentially select environment-goal pairings that optimized another person's goals. If children are systematically pairing based on outcomes, this may suggest that they are, in fact, attuned to the environment as a feature of goal optimization. 

## Methods

```{r e1-data}

## Load data
data_3b <- read_csv(here("data", "childrendatalog3b.csv"))

## Tidy data
tidydata_3b <- data_3b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "Yes") %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

## Remove extra spaces
tidydata_3b$activity <- str_trim(tidydata_3b$activity)
tidydata_3b$sound_type <- str_trim(tidydata_3b$sound_type)
tidydata_3b$race <- str_trim(tidydata_3b$race)
tidydata_3b$race <- str_replace(tidydata_3b$race, "/ ", "/")

## Turn response column into integers
tidydata_3b$response <- as.integer(tidydata_3b$response)

## Get demographic data
demodata_3b <- tidydata_3b %>%
  select(subject_id,race, trial, age_years, age_months) %>%
  filter(trial == 1) %>%  #get one value per participant
  mutate(race_count = ifelse((str_detect(race, ",")), "Multiracial", race))

excluded_3b <- data_3b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "No",
         trial == 1) %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

```

### Participants

`r nrow(demodata_3b)` children (3;0 - 5;11 years, mean age = `r round(mean(demodata_3b$age_months/12),2)` years , `r round(mean(demodata_3b$race == "Caucasian/White")*100,1)`% Caucasian/White) were recruited from either a local Bay Area nursery school or children’s museum. Participants were typically developing, had normal or corrected-to-normal vision, and heard English at least 75% of the time at home. An additional `r nrow(excluded_3b)` children were ultimately excluded from analysis due to response bias (provided the same pattern of responses for 100% of trials), experimenter error, or severe lapses in attention. Caregivers provided written consent while children provided verbal assent before participation. 

### Materials and Procedure

```{r e3-stimuli, fig.env = "figure", fig.pos = "t", fig.align='center', fig.width=3, fig.height=3, set.cap.width=T, fig.cap = "Experimental setup and stimuli. Participants were shown four wooden houses, each with an associated sound [instrumental music, multi-talker babble, silence, and white noise], and a list of four activities [dance, read, sleep, talk] that two charactrs in the game wanted to complete. Participants determined whether the two characters should or should not complete an activity in each of the four houses. Responses were independent of each other."}
figure1_23 <- png::readPNG(here("writeup","figs","figure1_23.png"))
grid::grid.raster(figure1_23)
```

A trained undergraduate research assistant served as the experimenter for the task. The experimenter first introduced participants to two small plastic figures named Joe and Mandy and to four wooden houses with a felt door on the front. The experimenter then showed participants a list of four images, each depicting one activity Joe and Mandy wanted to do together. The experimenter explained that when the door opened, each house would either play a sound or it wouldn't play anything at all. Joe and Mandy could choose whether or not to complete an activity in each house, and their decisions would be entirely based on participants' responses. Importantly, these decisions were independent of each other; participants could decide to have Joe and Mandy complete the same activity in more than one room if appropriate. A sound button was attached to the back of each house and hidden from the participant's view so when the experimenter opened the door, they also pressed down on the button to play the appropriate sound. The wooden houses were lined up on a table several inches apart with the participant seated facing the door of the house and the experimenter on the opposite side facing the sound buttons. Figure 1 illustrates the setup, the four activities, and the four auditory stimuli. 

The experimenter began the task with the first image on the list and told participants, "It looks like Joe and Mandy want to [sleep]. Let's look at each room and see if Joe and Mandy should [sleep] inside." The experimenter then opened the door to the first house [the experimenter always began with the first house on their left/the first house on the participant's right] and pressed down on the sound button. At the end of the audio clip, the experimenter closed the door and asked participants two questions. Participants only heard each audio once per trial. The experimenter repeated this process for the three remaining houses before moving on to the next activity. In total, participants completed 16 trials- 4 trials for each activity times 4 trials for each auditory stimulus. Trials were counterbalanced such that the presentation order was randomized into four conditions. 

Each auditory stimulus was 7s in length and equalized to a root mean square (RMS) of 65dB. The multi-talker babble was an overlay of five adult native English speakers reading short, unrelated sentences (@panfili2017). The white noise was engineered in Audacity. The instrumental music contained no human speech. Both the activities and auditory stimuli were selected based on a sample of adults run previously. One possible confound is the auditory stimuli suggests varying numbers of people inside the wooden houses. For example, the house paired with multi-talker babble may appear to have more figures or people inside than the houses paired with instrumental music, silence, and white noise. This may inadvertently influence children's decisions on whether or not a house is appropriate for a specific activity for reasons other than the auditory stimuli. To address this, we opened the top of each house and showed children that two other figures were inside. 

We asked participants two questions which served as our DVs: (1) "Should Joe and Mandy [read/dance/sleep/talk] in this room?" and (2) "Why did you say Joe and Mandy [should/shouldn't] [read/dance/sleep/talk] in this room?" 

## Results and Discussion

```{r e3b-bar, fig.pos = "t", fig.align='center', fig.width=7, fig.height=4, fig.env = 'figure*', fig.cap= "Results from Experiment 1. Participants' rating of the appropriateness of an auditory stimulus and activity pairing. Individual bars correspond to one age bin of 3, 4, or 5. A rating score of 0 indicates a rejection of the pairing [Joe and Mandy should not complete a particular activity in this environment] while a score of 1 indicates an affirmation of the pairing [Joe and Mandy should complete a particular activity in this environment]. A 2-alternative forced choice design resulted in no preference at 50\\%.  Error bars show 95\\% confidence intervals."}

## Calculate confidence intervals

### Aggregate confidence intervals (3-5 years)
cidata_3b <- tidydata_3b %>%
  group_by(activity, sound_type) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

### Binned confidence intervals (by age)
cidataage_3b <- tidydata_3b %>%
  group_by(activity, sound_type, age_years) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

# Data visualization and stats

## x-axis labels
xlabels <- c("music", "babble", "silence", "white noise")

## Figure 2
### Binned Data
ggplot(data = cidataage_3b, mapping = aes(x = sound_type, fill = as.factor(age_years))) +
  geom_bar(aes(y = mean_response),
           position = "dodge", stat = "identity") +
  geom_linerange(aes(ymin = ci.l,
                     ymax = ci.u),
                 position = position_dodge(width = 0.9)) +
  facet_wrap(~activity, scales = "free", ncol = 4) +
  xlab("Auditory Stimulus") +
  ylim(0,1) +
  ylab("Rating") +
  scale_fill_manual(values = wes_palette("GrandBudapest1")) +
  scale_x_discrete(labels = xlabels) +
  geom_hline(yintercept = .5, lty =2) +
  theme_few() +
  theme(axis.text = element_text(size = 8),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        panel.spacing.x = unit(0.25, "lines"),
        panel.spacing.y = unit(0.25, "lines"),
        legend.direction = "horizontal",
        legend.position = "bottom",
        axis.text.x = element_text(angle = 30, hjust=1),
        text = element_text(size = 10)) +
  labs(fill = "Age (Years)")

```

```{r e3-stats-anova, echo=FALSE, results="hide", eval=FALSE}

mod <- lme4::glmer(response ~ sound_type * activity + (1|subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"),
                   data = tidydata_3b)
mod_noint <- lme4::glmer(response ~ sound_type + activity + (1|subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"), 
                   data = tidydata_3b)

options(scipen = 999)   
anova_3b <- anova(mod,mod_noint)

aov()

saveRDS(anova_3b, here("writeup/models","anova_3b.Rds"))

```

```{r e3-stats, echo=FALSE, results="hide", eval=FALSE}

tidydata_3b$activity <- factor(tidydata_3b$activity, 
                                   levels = c("dance","read","sleep","talk"))

glmer_3b <- stan_glmer(formula = response ~ sound_type * activity * age_years + (1 | subject_id),
                       family = binomial,
                       data = tidydata_3b)

summary_3b <- summary(glmer_3b, probs = c(0.025, 0.975))

saveRDS(summary_3b, here("writeup/models","summary_3b.Rds"))

```

```{r e3-stats-load}
summary_3b<- readRDS(here("writeup/models","summary_3b.Rds"))
anova_3b <- readRDS(here("writeup/models","anova_3b.Rds"))
```

If preschool children can reason about how the acoustic environment might influence goal optimization, and can make decisions to this end, we should expect participants to show clear preferences for activities paired with particular auditory stimuli. We preregistered [retracted] a Bayesian mixed-effects logistic regression from the `rstanarm` package to predict participants' response as a function of auditory stimulus, activity, and age, with a maximal random effect structure (random intercept by participant) [@goodrich2020]. In this and subsequent models, we used the package default of weakly informative priors (normal distributions on coefficients with SD=2.5, scaled to predictor magnitudes).

Figure 2 depicts children's activity-auditory pairings by age. We compared our model [activity and auditory stimulus as interactions] with a model with no interaction terms. A one-way ANOVA found that, on average, the interaction terms better predicted children's responses during the task [$X^2$(`r anova_3b[2,7]`) = `r round(anova_3b[2,6],2)`, p < 0.001]. 

These findings suggest that across the preschool years, children are evaluating the acoustic environments to make decisions about third-party goal optimization. We propose that this is evidence of basic environmental selection, and that children as young as three can reliably engage in it. 

# Experiment 2

In Experiment 1, we found that preschool children do engage in environmental selection, such that they may make decisions about optimal environments for goal selection based on auditory information. We also found that this ability was generally stable across the preschool years. However, it is possible that children succeeded in this task not because they were engaging in some cognitively flexible process, but because they were relying on pure associations. For example, children may have paired napping with silence because they have learned that any sleeping activity is best done in quiet, and not because they recognize that silence might be the most optimal auditory environment to both fall and stay asleep. 

Young children harness associative learning in a host of contexts. For example, associative models of word learning suggest that children exploit contextual information to acquire the meanings of novel words [@sloutsky2017]. This is especially helpful given referential uncertainty of unfamiliar words that co-occur with other referents with varying individual probabilities [@quine1960]. Some of the most convincing associative models of word learning are probabilistic at their core and suggest that word learning happens, in part, because learners are constantly assessing the probabilities that a word's meaning is associated with an unfamiliar word. Moreover, these probabilities are updated as the lexicon expands [see @stevens2017]. But associative learning is not relegated to language development; indeed, humans can develop associative links from third-party social interactions [@thiele2021], to remember sequences of stimuli without overloading our cognitive system [@tosatto2022], and even to recognize potential environmental threats, such as snakes and spiders, in infancy [@rakison2022]. One possibility, then, is that environmental selection is driven by associative learning for young children.

While some unifying accounts of active and associative learning exist [see @kruschke2008], traditional associative accounts view the learner as a passive agent, one who learns what is true about their environment but does not necessarily act on their environment. It is possible that reasoning about the acoustic environment, while beneficial, is not necessary for goal optimization. In other words, perhaps children can still reach the same decision point with association alone. To test this, we replaced the familiar activities in Experiment 1 with novel ones. If children primarily reason about the pairing between the acoustic environment and a set of goals through pure association, they should have trouble pairing acoustic environments with novel activities because they have not previously reasoned about these pairings. If, however, children are actively updating information about their environment and then using this information to inform new goals, they should also succeed even when faced with goals they have never encountered.

## Methods

```{r e4-data}

## Load data
data_4b <- read_csv(here("data", "childrendatalog4b.csv")) #load data

## Tidy data
tidydata_4b <- data_4b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "Yes") %>% #exclude pilot participants and those who could not be retained for analysis failed attention and sound checks
  select(subject_id:rationale) %>%
  na.omit()

## Remove extra spaces
tidydata_4b$activity <- str_trim(tidydata_4b$activity)
tidydata_4b$sound_type <- str_trim(tidydata_4b$sound_type)
tidydata_4b$race <- str_trim(tidydata_4b$race)
tidydata_4b$race <- str_replace(tidydata_4b$race, "$/$ ", "$/$")

## Turn response column into integers
tidydata_4b$response <- as.integer(tidydata_4b$response)
tidydata_4b$age_months <- as.integer(tidydata_4b$age_months)

## Demographic information
demodata_4b <- tidydata_4b %>%
  select(subject_id,race, trial, age_years, age_months) %>%
  filter(trial == 1) %>%  #get one value per participant
  mutate(race_count = ifelse((str_detect(race, ",")), "Multiracial", race)) 

excluded_4b <- data_4b %>%
  clean_names() %>%  #lowercase column names
  filter(arm == "Main",
         included == "No",
         trial == 1) %>% #exclude pilot participants and those who could not be retained for analysis for failed attention and sound checks
  select(subject_id:rationale)
```

```{r e4adult-data}
#Adult Data
#Load data 4a
data_4a <- read.csv(here("data", "adultdatalog4a1.csv"), na.strings = c("", "NA")) #load data

## Clean data
cleandata_4a <- data_4a %>% 
  clean_names() %>% #lowercase column names
  select(q6:language_1) %>% #remove unnecessary columns
  rename("sound_check" = "q6")

## Remove first two rows (contain no data/are unnecessary)
cleandata_4a <- cleandata_4a[-c(1,2), ]

## Data cleaning and participant exclusion
tidydata_4a <- cleandata_4a %>% 
  filter(attention_check_1 == 1,
         attention_check_2 == 1,
         sound_check == 1) %>% #exclude participants who failed attention and sound checks
  mutate(subject_id = row_number()) %>% #make a subject id column
  select(subject_id, everything()) %>%
  relocate(age, race, .after = subject_id) %>% 
  select(subject_id:rast_white)

## Pivot columns
tidy4a <- tidydata_4a %>%
  pivot_longer(cols = c("clop_instrumental", "fraw_instrumental", "gobb_instrumental", "norl_instrumental", "terb_instrumental", "plip_instrumental", "surk_instrumental", "rast_instrumental",
                        "clop_silence", "fraw_silence", "gobb_silence", "norl_silence", "terb_silence", "plip_silence", "surk_silence", "rast_silence",
                        "clop_white", "fraw_white", "gobb_white", "norl_white", "terb_white", "plip_white", "surk_white", "rast_white",
                        "clop_mtb", "fraw_mtb", "gobb_mtb", "norl_mtb", "terb_mtb", "plip_mtb", "surk_mtb", "rast_mtb"),
               names_to = "activity",
               values_to = "rating") %>% 
  separate(col = activity,
           into = c("activity", "noise_type"),
           sep = '[_]') %>% 
  na.omit()

## Make rating category numeric
tidy4a$rating <- as.integer(tidy4a$rating)

##Pull out 4 activities that relate to Experiment 2
tidy_data4b_exp2 <- tidy4a %>% 
  filter(activity %in% c("fraw", "gobb", "plip", "clop")) %>%
  rename("activity_old" = "activity") %>% 
  mutate(activity = case_when(
            activity_old == "clop" ~ "terb",
            activity_old == "gobb" ~ "gobb",
            activity_old == "fraw" ~ "fraw",
            activity_old == "plip" ~ "plip"))

## Demographic information
demodata_4a <- tidydata_4a %>%
  select(subject_id,age, race) %>% 
  replace(is.na(tidydata_4a$race), 7)

## Make race and age categories numeric
demodata_4a$race <- as.integer(demodata_4a$race, na.rm = TRUE)
demodata_4a$age <- as.integer(demodata_4a$age, na.rm = TRUE)

excluded_4a <- cleandata_4a %>%
  filter(attention_check_1 == 0 | attention_check_2 == 0)

```

### Participants

`r nrow(demodata_4b)` children (3;0 - 5;11 years, mean age = `r round(mean(demodata_4b$age_months/12),2)` years, `r round(mean(demodata_4b$race == "Caucasian/White")*100,1)`% Caucasian/White) were recruited from either a local Bay Area nursery school or children’s museum. An additional `r nrow(excluded_4b)` children were ultimately excluded from analysis.

### Materials and Procedure

The procedures for Experiment 2 were nearly identical to Experiment 1 with one notable difference. To determine whether preschool children use environmental selection flexibly to novel activities, we presented participants with a new list of activities- (1) Fraw: when someone reads you a bedtime story right before you fall asleep, (2) Gobb: when you are looking for something to do because you are really bored, (3) Plip: when you spin around in circles to the beat until you get really dizzy, and (4) Terb: when you don't want anyone else to know your tummy is making noise. We selected these novel activities based on an adult sample we previously ran online, where we found these four activities elicited the widest distribution of responses among participants. 

We asked participants two questions which served as our DVs: (1) "Should Joe and Mandy [fraw/gobb/plip/terb] in this room?" and (2) "Why did you say Joe and Mandy [should/shouldn't] [fraw/gobb/plip/terb] in this room?"

## Results and Discussion

```{r e4b-bar, fig.env = "figure*", fig.pos = "t", fig.align='center', fig.width=7, fig.height=4, fig.cap = "Results from Experiment 2. Data is collapsed acrossed age."}

## Calculate confidence intervals

### Aggregate confidence intervals (3-5 years)
cidata_4b <- tidydata_4b %>%
  group_by(activity, sound_type) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

### Binned confidence intervals (by age)
cidataage_4b <- tidydata_4b %>%
  group_by(activity, sound_type, age_years) %>%
  summarise(ci.l = binom::binom.bayes(x = sum(response), n = n())$lower,
            ci.u = binom::binom.bayes(x = sum(response), n = n())$upper,
            n = n(),
            mean_response = mean(response)) %>% 
  mutate(activity = fct_reorder(activity, mean_response, .desc = TRUE))

# Data visualization and stats

## x-axis labels
xlabels <- c("babble", "music", "silence", "white noise")

#Figure 3
 ## Aggregated Data
 ggplot(data = cidata_4b, mapping = aes(x = sound_type, y = mean_response, fill = activity)) +
   geom_col() +
   geom_linerange(aes(ymin = ci.l,
                      ymax = ci.u)) +
   ylim(0,1) +
   xlab("Auditory Stimulus") +
   ylab("Rating") +
   #scale_fill_brewer(palette="Set2") +
   scale_fill_manual(values = wes_palette("GrandBudapest1")) +
   scale_x_discrete(labels = xlabels) +
   facet_wrap(~activity) +
   geom_hline(yintercept = .5, lty =2) +
   scale_color_solarized() + 
   theme_few() +
   theme(legend.position = "none",
         title = element_text(size = 8),
         axis.text = element_text(size = 8),
         panel.spacing.x = unit(0.5, "lines"),
         panel.spacing.y = unit(0.5, "lines"),
         axis.text.x = element_text(angle = 30, hjust=1),
         text = element_text(size=10))

## Binned Data
# ggplot(data = cidataage_4b, mapping = aes(x = sound_type, fill = as.factor(age_years))) +
#   geom_bar(aes(y = mean_response),
#            position = "dodge", stat = "identity") +
#   geom_linerange(aes(ymin = ci.l,
#                      ymax = ci.u),
#                  position = position_dodge(width = 0.9)) +
#   facet_wrap(~activity, scales = "free", ncol = 4) +
#   xlab("Auditory Stimulus") +
#   ylim(0,1) +
#   ylab("Rating") +
#   scale_fill_manual(values = wes_palette("GrandBudapest1")) +
#   scale_x_discrete(labels = xlabels) +
#   geom_hline(yintercept = .5, lty =2) +
#   theme_few() +
#   theme(axis.text = element_text(size = 8),
#         legend.text = element_text(size = 8),
#         legend.title = element_text(size = 8),
#         panel.spacing.x = unit(0.25, "lines"),
#         panel.spacing.y = unit(0.25, "lines"),
#         legend.direction = "horizontal",
#         legend.position = "bottom",
#         axis.text.x = element_text(angle = 30, hjust=1),
#         text = element_text(size = 10)) +
#   labs(fill = "Age (Years)")
```

```{r e4-stats-anova, results='hide', eval=FALSE}

mod4 <- lme4::glmer(response ~ sound_type * activity  + (1 | subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"), 
                   data = tidydata_4b)
mod4_noint <- lme4::glmer(response ~ sound_type + activity  + (1 | subject_id), 
                   family = binomial, 
                  control = glmerControl(optimizer = "bobyqa"), 
                   data = tidydata_4b)

anova_4b <- anova(mod4, mod4_noint)

saveRDS(anova_4b, here("writeup/models","anova_4b.Rds"))
```

```{r e4-stats-anova-load}
anova_4b <- readRDS(here("writeup/models","anova_4b.Rds"))
```

```{r e4-stats, results="hide", eval=FALSE}

# Logistic Regression
glmer_4b <- stan_glmer(formula = response ~ sound_type * activity * age_years + (1 | subject_id),
                       family = binomial,
                       data = tidydata_4b)

summary_4b <- summary(glmer_4b, probs = c(0.025, 0.975))

saveRDS(summary_4b, here("writeup/models","summary_4b.Rds"))

```

```{r e4-stats-load}
summary_4b <- readRDS(here("writeup/models","summary_4b.Rds"))
```

```{r e4a-bar, fig.env = "figure*", fig.pos = "t", fig.align='center', fig.width=7, fig.height=4, fig.cap = "Results from an adult sample. Adult participants completed the same task as children in Experiment 2, but instead of reasoning about a third party (Joe and Mandy in Exp. 2), they were asked how well they could complete each activity based on the ausitory stimulus. The y-axis indicates the rating scale from 1-7. A rating of 1 denotes a full mismatch between activity and auditory stimulus while 7 denotes an optimal match."}

## Calculate confidence intervals
cidata_4a <- tidy_data4b_exp2 %>%
  group_by(activity, noise_type) %>% 
  summarise(n = n(),
            mean_rating = mean(rating, na.rm=TRUE), 
            sem = sd(rating) / sqrt(n),
            ci.l = mean_rating - sem * 1.96,
            ci.u = mean_rating + sem * 1.96)

# Data Visualization

xlabels <- c("babble", "music", "silence", "white noise")

ggplot(data = cidata_4a, 
       mapping = aes(x = factor(noise_type, level= c("mtb", "instrumental", "silence", "white")), y = mean_rating, fill = activity)) +
  geom_col() +
  geom_linerange(aes(ymin = ci.l,
                     ymax = ci.u)) +
  ylim(0,7) +
  xlab("Auditory Stimulus") +
  ylab("Rating") +
  #scale_fill_brewer(palette="Set2") +
  scale_fill_manual(values = wes_palette("GrandBudapest1")) +
  scale_x_discrete(labels = xlabels) +
  facet_wrap(~activity) +
  geom_hline(yintercept = 3.5, lty =2) +
  scale_color_solarized() + 
  theme_few() +
  theme(legend.position = "none",
        title = element_text(size = 8),
        axis.text = element_text(size = 8),
        panel.spacing.x = unit(0.5, "lines"),
        panel.spacing.y = unit(0.5, "lines"),
        axis.text.x = element_text(angle = 30, hjust=1),
        text = element_text(size=10))
```

If preschool children rely solely on association when evaluating the acoustic environment, that is, they have acquired associative links between familiar activities and their acoustic contexts, we should expect that children will have no strong preferences for pairing novel activities with any particular acoustic context. If, however, children can reason flexibly about how the acoustic environment influences goal optimization and outcomes, we should expect that children show clear preferences for acoustic contexts even with activities they have never actually encountered.

Data collection for Experiment 2 is ongoing, so we present a subset [20 of the preregistered 72-participant sample] of the data for preliminary analysis. Our model with an interaction between activity and auditory stimulus was not different from a model with no interaction term  [$X^2$(`r anova_4b[2,7]`) = `r round(anova_4b[2,6],2)`, p = `r round(anova_4b[2,8],2)`]. Figure 3 shows the aggregated data across all participants.

## Adult Ratings of Novel Activity Pairings

The previous findings suggest some differentiation in pairing auditory stimuli with novel activities, but what pattern of results should we expect? Given the novelty of the paradigm, we recruited a sample of adult participants to complete the same task, and then we compared these results with children in the previous sample. 

`r nrow(demodata_4a)` adults (mean age = `r round(mean(demodata_4a$age),2)` years, `r round(mean(demodata_4a$race == 3)*100,1)`% Caucasian/White) were recruited for an online study hosted on Prolific. An additional `r nrow(excluded_4a)` participants were ultimately excluded from analysis for failing one or both of the attention checks.

# General Discussion

In this set of Experiments, we explored preschool children's reasoning about their acoustic environments. To this end, we asked if children engage in environmental selection for goal optimization. In Experiment 1, we found that across the preschool years, children can reliably evaluate the acoustic environment to inform their decisions about third-party goals. In Experiment 2, we asked whether children are primarily relying on associations or on active learning when assessing activity feasibility by asking them to reason about novel activities. Preliminary results show a trend in children's flexibility on this task, in that they can reason about activities they have not previously encountered.

These findings support the notion that young children are attuned to environmental features and can integrate this information for decision-making related to optimizing goals. That learning is situated in an imperfect and often messy environment is all the more reason why strategic exploration matters. If you can identify what is best learned in a particular environment given the acoustic constraints, you might both maximize your efficiency and reduce uncertainty, which bolsters skills building. Environmental selection offers a window into reasoning about the acoustic context, and it highlights the value of active learning in early childhood. Perhaps most advantageous, active learning seems to be flexible, and supports children's exploration across a range of experiences.

This work is not without its limitations, which fuel our future directions. Without our full sample size in Experiment 2, we are limited in what we can conclude about the results. However, the preliminary findings are promising, and they offer some ground for broaching our main research questions. Additionally, this set of experiments explored children's reasoning about the goals of others; it is possible that children's preferences for certain acoustic environments may vary if they were instead asked to reason about their own goals. This work also does not directly test a strategy children might use to extract information from the environment under noise constraints. Instead, it lays the foundation for understanding how children evaluate acoustic environments with varying degrees of noise, and a possible mechanism that drives it. By exploring children's environmental evaluations and their flexibility beyond familiar associations, we might later manipulate children's own acoustic environments to observe the utility of environmental selection in action. We believe the current studies are critical interim steps to this end because they will inform the direction of future research.

This research also has potential utility in intervention efforts. Environmental noise exposure is here to stay; noise pollution in the United States affects everyone at some time or another, but some evidence suggests that it disproportionately affects communities of color and those of lower socioeconomic status, who tend to reside in more densely populated regions [@casey2017]. This could have downstream consequences on linguistic and cognitive skills, as well as on academic achievement. Future research should be sensitive to both the acute and chronic effects of noise exposure on children, in particular, and study strategies that can be implemented to ameliorate these effects. We believe that environmental selection could be one such strategy, and that by three years, children have the hardware to use it effectively. 

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent

